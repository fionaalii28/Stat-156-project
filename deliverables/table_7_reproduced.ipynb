{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e31b5499-7b03-4bad-90b2-6d641688ba22",
   "metadata": {},
   "source": [
    "**Replication of Table 7: Educational Outcomes and Television Coverage**\n",
    "\n",
    "*To replicate the original paper’s results, we focus on recreating Table 7, which examines the relationship between exposure to educational television and later academic outcomes. Because constructing this table directly from IPUMS microdata proved infeasible, we rely on the authors’ replication datasets and reconstruct the analysis step by step, including the creation of state-level television coverage measures and the estimation of regression models linking coverage to standardized test scores.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c7dae83-b019-4cc3-b2ef-fcd0aa88e1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14866, 15)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "cov = pd.read_stata(\"coverage.dta\")\n",
    "# Inspect dataset dimensions to confirm successful load\n",
    "cov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64177f2a-844e-4530-9481-0f1f95592a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov[\"covrate_raw\"] = cov[\"covrate\"]\n",
    "# Preserve the original categorical coverage variable for transparency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e89229f9-e97a-4f7d-911c-0bd4a3742cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "covrate_raw\n",
       "over 50%    8195\n",
       "5-24%       4013\n",
       "25-50%      2526\n",
       ".            132\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov[\"covrate_raw\"].value_counts(dropna=False)\n",
    "# Examine the distribution of coverage categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38e1d7b5-378a-4f2b-915d-b706ff151b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "covrate_map = {\n",
    "    \"5-24%\": 0.15,\n",
    "    \"25-50%\": 0.375,\n",
    "    \"over 50%\": 0.75,\n",
    "    \".\": np.nan\n",
    "}\n",
    "\n",
    "cov[\"covrate\"] = cov[\"covrate_raw\"].map(covrate_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3850f8ec-f076-4095-84e8-38240de541f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "covrate\n",
       "0.750    8195\n",
       "0.150    4013\n",
       "0.375    2526\n",
       "NaN       132\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov[\"covrate\"].value_counts(dropna=False)\n",
    "# Map categorical coverage bins to midpoint numeric values.\n",
    "# This approximates continuous coverage intensity as in the original paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b501cad8-4bb3-4eb0-a263-627c7617daa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14733, 17)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov[\"state_clean\"] = cov[\"state_hh\"].str.strip().str.upper()\n",
    "# Standardize state names to enable merging later\n",
    "cov[\"tvhomes\"] = pd.to_numeric(cov[\"tvhomes\"], errors=\"coerce\")\n",
    "# Convert number of TV-owning households to numeric\n",
    "\n",
    "cov = cov.dropna(subset=[\"covrate\", \"tvhomes\", \"state_clean\"])\n",
    "# Drop observations with missing key variables\n",
    "cov.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4b9e375-81b9-4754-9aa4-5d982881b201",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov[\"weighted_cov\"] = cov[\"covrate\"] * cov[\"tvhomes\"]\n",
    "# Create household-weighted coverage at the market level\n",
    "\n",
    "# Aggregate to the state level:\n",
    "# Numerator: total weighted coverage\n",
    "# Denominator: total TV households\n",
    "state_cov = (\n",
    "    cov\n",
    "    .groupby(\"state_clean\", as_index=False)\n",
    "    .agg(\n",
    "        total_weighted_cov=(\"weighted_cov\", \"sum\"),\n",
    "        total_tvhomes=(\"tvhomes\", \"sum\")\n",
    "    )\n",
    ")\n",
    "\n",
    "state_cov[\"covrate_state\"] = (\n",
    "    state_cov[\"total_weighted_cov\"] / state_cov[\"total_tvhomes\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d741fcb7-d397-439f-87a7-80cf79fb6b54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_clean</th>\n",
       "      <th>total_weighted_cov</th>\n",
       "      <th>total_tvhomes</th>\n",
       "      <th>covrate_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>2195797.5</td>\n",
       "      <td>4345700.0</td>\n",
       "      <td>0.505281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>1342192.5</td>\n",
       "      <td>2034500.0</td>\n",
       "      <td>0.659716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ARKANSAS</td>\n",
       "      <td>1348440.0</td>\n",
       "      <td>2287100.0</td>\n",
       "      <td>0.589585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>26151727.5</td>\n",
       "      <td>41247900.0</td>\n",
       "      <td>0.634014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COLORADO</td>\n",
       "      <td>1588417.5</td>\n",
       "      <td>2304800.0</td>\n",
       "      <td>0.689178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  state_clean  total_weighted_cov  total_tvhomes  covrate_state\n",
       "0     ALABAMA           2195797.5      4345700.0       0.505281\n",
       "1     ARIZONA           1342192.5      2034500.0       0.659716\n",
       "2    ARKANSAS           1348440.0      2287100.0       0.589585\n",
       "3  CALIFORNIA          26151727.5     41247900.0       0.634014\n",
       "4    COLORADO           1588417.5      2304800.0       0.689178"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute state-level average television coverage\n",
    "state_cov.shape\n",
    "state_cov[\"covrate_state\"].describe()\n",
    "state_cov.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2efc48f2-0ac4-416d-8a40-6d7864bab463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['RECDTYPE', 'SCHLTYPE', 'schoolid', 'STUDNTID', 'ID', 'censusregion',\n",
       "       'TWINDATA', 'grade', 'DESIGNWT', 'grades_sofar',\n",
       "       ...\n",
       "       'att_acptlife_sryr', 'scale_acptlife_sryr', 'att_stsfy_self_sryr',\n",
       "       'scale_stsfy_self_sryr', 'att_neg_self_sryr', 'daily_friends',\n",
       "       'daily_read', 'daily_phone', 'daily_tlkprnt', 'hrsday_tv'],\n",
       "      dtype='object', length=525)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now loading the longitudinal student-level dataset used for achievement outcomes\n",
    "\n",
    "df = pd.read_stata(\"allyrs_v1.dta\")\n",
    "df.shape\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d67e98a-90ff-4995-aac7-d44104d5d706",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12450/277794326.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"soph_1980\"] = (df[\"grade\"] == \"SOPHOMORE\").astype(int)\n"
     ]
    }
   ],
   "source": [
    "# Create an indicator for students who were sophomores in 1980.\n",
    "# These students were age-eligible for early childhood TV exposure.\n",
    "df[\"soph_1980\"] = (df[\"grade\"] == \"SOPHOMORE\").astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c13c6118-75bd-453b-994b-7b6c16b180dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5318812719927016)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"grade\"].value_counts(dropna=False)\n",
    "df[\"soph_1980\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22ad1893-e6b8-4a70-a2d5-ad4e9b12c268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12450/624005393.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[\"state_clean\"] = df[\"state\"].astype(str).str.strip().str.upper()\n"
     ]
    }
   ],
   "source": [
    "df[\"state_clean\"] = df[\"state\"].astype(str).str.strip().str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b102af05-b600-4e8b-b5fc-4bca1ea40eec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state_clean\n",
       "CALIFORNIA      6535\n",
       "TEXAS           4588\n",
       "NEW YORK        4371\n",
       "ILLINOIS        4352\n",
       "PENNSYLVANIA    3377\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"state_clean\"].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cae2c51-8301-46df-b720-6eaaef1658f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge state-level TV coverage into the student-level dataset\n",
    "df = df.merge(\n",
    "    state_cov[[\"state_clean\", \"covrate_state\"]],\n",
    "    on=\"state_clean\",\n",
    "    how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c971d33e-4473-4b8b-a50a-fe96d59ea8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.0009774534080542162)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"covrate_state\"].describe()\n",
    "df[\"covrate_state\"].isna().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3930d94a-ca4f-4510-b906-d39e84bdb1a3",
   "metadata": {},
   "source": [
    "**Construction of the Television Coverage × Sophomore Cohort Interaction**\n",
    "\n",
    "**Interpretation:**\n",
    "This table illustrates the creation of the key interaction variable used in the Table 7 replication. The variable cov_x_soph captures differential exposure to educational television by interacting state-level television coverage (covrate_state) with an indicator for being a sophomore in 1980. For students in the sophomore cohort, the interaction equals the state’s coverage rate, while for all other students it is zero, ensuring that variation in coverage is only attributed to the age-eligible cohort relevant for identifying the treatment effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e6a7b52-10ed-4156-bf0b-a3901b07fd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interaction between state TV coverage and being in the treated cohort.\n",
    "# For non-sophomores, this equals zero by construction.\n",
    "df[\"cov_x_soph\"] = df[\"covrate_state\"] * df[\"soph_1980\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "39483146-90d9-45cd-9514-80c462ea96ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>covrate_state</th>\n",
       "      <th>soph_1980</th>\n",
       "      <th>cov_x_soph</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.416667</td>\n",
       "      <td>1</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   covrate_state  soph_1980  cov_x_soph\n",
       "0       0.416667          1    0.416667\n",
       "1       0.416667          0    0.000000\n",
       "2       0.416667          0    0.000000\n",
       "3       0.416667          1    0.416667\n",
       "4       0.416667          0    0.000000\n",
       "5       0.416667          0    0.000000\n",
       "6       0.416667          0    0.000000\n",
       "7       0.416667          0    0.000000\n",
       "8       0.416667          1    0.416667\n",
       "9       0.416667          1    0.416667"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"covrate_state\", \"soph_1980\", \"cov_x_soph\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14480d47-1f4e-40a7-834b-7eac00632055",
   "metadata": {},
   "source": [
    "**Baseline Effect of Television Coverage on Math Achievement**\n",
    "\n",
    "**Results and Interpretation**\n",
    "This table reports results from a baseline OLS regression replicating the core specification underlying Table 7 of the original paper. The dependent variable is standardized math achievement, constructed by normalizing math percentile scores within sophomore status. The key explanatory variable is the interaction between state-level television coverage and an indicator for being a sophomore in 1980, which captures differential exposure to television for the treated cohort.\n",
    "In this baseline specification, the coefficient on the television coverage–sophomore interaction is negative and statistically insignificant. This contrasts with the original paper’s findings and likely reflects the absence of additional controls and fixed effects included in the published specification. Without demographic controls and regional adjustments, the model explains virtually none of the variation in math achievement (R² ≈ 0), suggesting substantial omitted-variable bias at this stage of the replication.\n",
    "\n",
    "Importantly, this result is not interpreted as evidence against the paper’s main conclusions. Rather, it serves as a diagnostic benchmark, confirming that the raw interaction alone is insufficient to recover the treatment effect. As shown in subsequent specifications, introducing demographic controls, census region fixed effects, and additional outcome standardizations substantially alters both the magnitude and significance of the estimates, bringing the replication closer to the original results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a8e282d-b9ff-4070-a8bc-87f1ce74f45d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               math_std   R-squared:                       0.000\n",
      "Model:                            OLS   Adj. R-squared:                 -0.000\n",
      "Method:                 Least Squares   F-statistic:                    0.2359\n",
      "Date:                Fri, 12 Dec 2025   Prob (F-statistic):              0.790\n",
      "Time:                        06:53:58   Log-Likelihood:                -70828.\n",
      "No. Observations:               49920   AIC:                         1.417e+05\n",
      "Df Residuals:                   49917   BIC:                         1.417e+05\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:                  HC1                                         \n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      0.0001      0.006      0.018      0.986      -0.012       0.013\n",
      "cov_x_soph    -0.0597      0.087     -0.685      0.493      -0.231       0.111\n",
      "soph_1980      0.0337      0.051      0.665      0.506      -0.066       0.133\n",
      "==============================================================================\n",
      "Omnibus:                    10298.003   Durbin-Watson:                   1.621\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2111.765\n",
      "Skew:                           0.122   Prob(JB):                         0.00\n",
      "Kurtosis:                       2.022   Cond. No.                         26.9\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC1)\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Baseline regression replicating the simplest Table 7 specification\n",
    "model_math_std = smf.ols(\n",
    "    \"math_std ~ cov_x_soph + soph_1980\",\n",
    "    data=df\n",
    ").fit(cov_type=\"HC1\")\n",
    "\n",
    "print(model_math_std.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6699fa0a-0071-4364-8232-79debb7877af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize outcomes within sophomore status groups\n",
    "# This matches the paper’s normalization strategy\n",
    "for v in [\"math_pctsryr\", \"vocab_pctsryr\", \"read_pctsryr\"]:\n",
    "    df[v + \"_std\"] = (\n",
    "        df.groupby(\"soph_1980\")[v]\n",
    "          .transform(lambda x: (x - x.mean()) / x.std())\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77358d9a-e688-409a-a0bd-1eab3ffe4c2e",
   "metadata": {},
   "source": [
    "**Baseline Replication of Table 7: Television Coverage and Standardized Math Achievement**\n",
    "\n",
    "**Results and Interpretation:**\n",
    "This regression replicates the baseline specification underlying Table 7 by estimating the relationship between state-level television coverage interacted with sophomore status (cov_x_soph) and standardized math achievement. The coefficient on the interaction term is negative and statistically insignificant, indicating no detectable association between television coverage exposure and math outcomes in this simple specification. This lack of precision and explanatory power (R² ≈ 0) is expected at this stage of the replication, as the original paper’s results rely on additional controls and richer specifications; accordingly, subsequent regressions extend this framework to include demographic and regional covariates to better align with the published findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77dae46a-6494-4c85-b10c-a91c21859d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>math_pctsryr_std</td> <th>  R-squared:         </th> <td>   0.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>  0.2359</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 12 Dec 2025</td> <th>  Prob (F-statistic):</th>  <td> 0.790</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>06:54:04</td>     <th>  Log-Likelihood:    </th> <td> -70828.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td> 49920</td>      <th>  AIC:               </th> <td>1.417e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td> 49917</td>      <th>  BIC:               </th> <td>1.417e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>         <td>HC1</td>       <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>         <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>  <td>    0.0001</td> <td>    0.006</td> <td>    0.018</td> <td> 0.986</td> <td>   -0.012</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cov_x_soph</th> <td>   -0.0597</td> <td>    0.087</td> <td>   -0.685</td> <td> 0.493</td> <td>   -0.231</td> <td>    0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>soph_1980</th>  <td>    0.0337</td> <td>    0.051</td> <td>    0.665</td> <td> 0.506</td> <td>   -0.066</td> <td>    0.133</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>10298.003</td> <th>  Durbin-Watson:     </th> <td>   1.621</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>2111.765</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 0.122</td>   <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 2.022</td>   <th>  Cond. No.          </th> <td>    26.9</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors are heteroscedasticity robust (HC1)"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    & math\\_pctsryr\\_std & \\textbf{  R-squared:         } &     0.000   \\\\\n",
       "\\textbf{Model:}            &        OLS         & \\textbf{  Adj. R-squared:    } &    -0.000   \\\\\n",
       "\\textbf{Method:}           &   Least Squares    & \\textbf{  F-statistic:       } &    0.2359   \\\\\n",
       "\\textbf{Date:}             &  Fri, 12 Dec 2025  & \\textbf{  Prob (F-statistic):} &    0.790    \\\\\n",
       "\\textbf{Time:}             &      06:54:04      & \\textbf{  Log-Likelihood:    } &   -70828.   \\\\\n",
       "\\textbf{No. Observations:} &        49920       & \\textbf{  AIC:               } & 1.417e+05   \\\\\n",
       "\\textbf{Df Residuals:}     &        49917       & \\textbf{  BIC:               } & 1.417e+05   \\\\\n",
       "\\textbf{Df Model:}         &            2       & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &        HC1         & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                      & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}    &       0.0001  &        0.006     &     0.018  &         0.986        &       -0.012    &        0.013     \\\\\n",
       "\\textbf{cov\\_x\\_soph} &      -0.0597  &        0.087     &    -0.685  &         0.493        &       -0.231    &        0.111     \\\\\n",
       "\\textbf{soph\\_1980}   &       0.0337  &        0.051     &     0.665  &         0.506        &       -0.066    &        0.133     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 10298.003 & \\textbf{  Durbin-Watson:     } &    1.621  \\\\\n",
       "\\textbf{Prob(Omnibus):} &    0.000  & \\textbf{  Jarque-Bera (JB):  } & 2111.765  \\\\\n",
       "\\textbf{Skew:}          &    0.122  & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &    2.022  & \\textbf{  Cond. No.          } &     26.9  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors are heteroscedasticity robust (HC1)"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:       math_pctsryr_std   R-squared:                       0.000\n",
       "Model:                            OLS   Adj. R-squared:                 -0.000\n",
       "Method:                 Least Squares   F-statistic:                    0.2359\n",
       "Date:                Fri, 12 Dec 2025   Prob (F-statistic):              0.790\n",
       "Time:                        06:54:04   Log-Likelihood:                -70828.\n",
       "No. Observations:               49920   AIC:                         1.417e+05\n",
       "Df Residuals:                   49917   BIC:                         1.417e+05\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:                  HC1                                         \n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept      0.0001      0.006      0.018      0.986      -0.012       0.013\n",
       "cov_x_soph    -0.0597      0.087     -0.685      0.493      -0.231       0.111\n",
       "soph_1980      0.0337      0.051      0.665      0.506      -0.066       0.133\n",
       "==============================================================================\n",
       "Omnibus:                    10298.003   Durbin-Watson:                   1.621\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2111.765\n",
       "Skew:                           0.122   Prob(JB):                         0.00\n",
       "Kurtosis:                       2.022   Cond. No.                         26.9\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors are heteroscedasticity robust (HC1)\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.ols(\n",
    "    \"math_pctsryr_std ~ cov_x_soph + soph_1980\",\n",
    "    data=df\n",
    ").fit(cov_type=\"HC1\").summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89cb6d7e-2002-4847-8c7e-f9dfa21b4081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'read_pctsryr_std  ~ cov_x_soph + soph_1980'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"vocab_pctsryr_std ~ cov_x_soph + soph_1980\"\n",
    "\"read_pctsryr_std  ~ cov_x_soph + soph_1980\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "572a5e3d-2dc5-48c2-980d-77fe42180c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "controls = [\n",
    "    \"black\",\n",
    "    \"hisp\",\n",
    "    \"singleparentsr\",\n",
    "    \"censusregion\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f3a7d2-cefd-48e0-a830-d7125fb54743",
   "metadata": {},
   "source": [
    "**Math Achievement Regressions with State Television Coverage**\n",
    "\n",
    "**Interpretation:**\n",
    "This table reports OLS estimates replicating Table 7 of the paper, relating standardized math achievement to state-level television coverage and sophomore status in 1980. The interaction between coverage and being a sophomore is positive and statistically significant once demographic and regional controls are included, indicating higher math scores for sophomores in high-coverage states. Differences in magnitudes relative to the original results likely reflect sample construction and coding choices, but the qualitative pattern is consistent with the paper’s findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b11cd5c-506f-46eb-8246-a1811a835b06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               math_std   R-squared:                       0.139\n",
      "Model:                            OLS   Adj. R-squared:                  0.138\n",
      "Method:                 Least Squares   F-statistic:                     713.1\n",
      "Date:                Fri, 12 Dec 2025   Prob (F-statistic):               0.00\n",
      "Time:                        07:15:58   Log-Likelihood:                -66743.\n",
      "No. Observations:               49678   AIC:                         1.335e+05\n",
      "Df Residuals:                   49664   BIC:                         1.336e+05\n",
      "Df Model:                          13                                         \n",
      "Covariance Type:                  HC1                                         \n",
      "======================================================================================================\n",
      "                                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Intercept                              0.3633      0.020     18.325      0.000       0.324       0.402\n",
      "censusregion[T.MIDDLE ATLANTIC]       -0.0183      0.022     -0.830      0.407      -0.061       0.025\n",
      "censusregion[T.SOUTH ATLANTIC]        -0.1393      0.022     -6.343      0.000      -0.182      -0.096\n",
      "censusregion[T.EAST SOUTH CENTRAL]    -0.3468      0.026    -13.444      0.000      -0.397      -0.296\n",
      "censusregion[T.WEST SOUTH CENTRAL]    -0.2688      0.023    -11.551      0.000      -0.314      -0.223\n",
      "censusregion[T.EAST NORTH CENTRAL]    -0.1156      0.021     -5.434      0.000      -0.157      -0.074\n",
      "censusregion[T.WEST NORTH CENTRAL]    -0.0603      0.024     -2.476      0.013      -0.108      -0.013\n",
      "censusregion[T.MOUNTAIN]              -0.2392      0.027     -8.913      0.000      -0.292      -0.187\n",
      "censusregion[T.PACIFIC]               -0.0742      0.023     -3.195      0.001      -0.120      -0.029\n",
      "cov_x_soph                             0.3700      0.087      4.244      0.000       0.199       0.541\n",
      "soph_1980                             -0.2089      0.051     -4.125      0.000      -0.308      -0.110\n",
      "black                                 -0.7644      0.012    -64.628      0.000      -0.788      -0.741\n",
      "hisp                                  -0.6591      0.012    -55.760      0.000      -0.682      -0.636\n",
      "singleparentsr                        -0.3324      0.013    -26.564      0.000      -0.357      -0.308\n",
      "==============================================================================\n",
      "Omnibus:                     2891.755   Durbin-Watson:                   1.774\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1100.742\n",
      "Skew:                           0.064   Prob(JB):                    9.48e-240\n",
      "Kurtosis:                       2.282   Cond. No.                         31.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC1)\n"
     ]
    }
   ],
   "source": [
    "# Estimate the controlled specification for math achievement\n",
    "formula = \"math_std ~ cov_x_soph + soph_1980 + \" + \" + \".join(controls)\n",
    "\n",
    "model_math_std_controls = smf.ols(\n",
    "    formula,\n",
    "    data=df\n",
    ").fit(cov_type=\"HC1\")\n",
    "\n",
    "print(model_math_std_controls.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fe6952ab-8c23-454d-b177-bd5a821d0b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in [\"math_pctsryr\", \"vocab_pctsryr\", \"read_pctsryr\"]:\n",
    "    df[v.replace(\"_pctsryr\", \"_std\")] = (\n",
    "        df.groupby(\"soph_1980\")[v]\n",
    "        .transform(lambda x: (x - x.mean()) / x.std())\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78791dc5-719a-4489-a370-718f995941c8",
   "metadata": {},
   "source": [
    "**Standardized Test Score Construction (Validation Step)**\n",
    "\n",
    "**Interpretation:**\n",
    "This table confirms that math, vocabulary, and reading scores were correctly standardized within sophomore status groups: each has mean ≈ 0 and standard deviation ≈ 1. This validation ensures the outcomes are comparable across subjects and suitable for the Table 7 regression analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4cd24942-a611-402a-a144-c4e060dd1ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>math_std</th>\n",
       "      <th>vocab_std</th>\n",
       "      <th>read_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.996200e+04</td>\n",
       "      <td>5.102800e+04</td>\n",
       "      <td>5.078500e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.016536e-08</td>\n",
       "      <td>6.159972e-08</td>\n",
       "      <td>-3.079700e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.999900e-01</td>\n",
       "      <td>9.999902e-01</td>\n",
       "      <td>9.999902e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.453766e+00</td>\n",
       "      <td>-2.637763e+00</td>\n",
       "      <td>-2.362017e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-8.241798e-01</td>\n",
       "      <td>-7.397979e-01</td>\n",
       "      <td>-6.960598e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.125148e-01</td>\n",
       "      <td>1.111522e-01</td>\n",
       "      <td>1.792209e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.054062e-01</td>\n",
       "      <td>7.663205e-01</td>\n",
       "      <td>7.477146e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.197716e+00</td>\n",
       "      <td>1.802792e+00</td>\n",
       "      <td>2.159867e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           math_std     vocab_std      read_std\n",
       "count  4.996200e+04  5.102800e+04  5.078500e+04\n",
       "mean   6.016536e-08  6.159972e-08 -3.079700e-08\n",
       "std    9.999900e-01  9.999902e-01  9.999902e-01\n",
       "min   -2.453766e+00 -2.637763e+00 -2.362017e+00\n",
       "25%   -8.241798e-01 -7.397979e-01 -6.960598e-01\n",
       "50%   -1.125148e-01  1.111522e-01  1.792209e-02\n",
       "75%    8.054062e-01  7.663205e-01  7.477146e-01\n",
       "max    2.197716e+00  1.802792e+00  2.159867e+00"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"math_std\", \"vocab_std\", \"read_std\"]].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19486c8-9bde-4938-9ecc-41be62fbc42b",
   "metadata": {},
   "source": [
    "**Replication of Table 7: Television Coverage and Student Achievement**\n",
    "\n",
    "**Key Results (Across All Outcomes):**\n",
    "Across math, vocabulary, and reading test scores, the interaction between state-level television coverage and sophomore status in 1980 (cov_x_soph) is positive and statistically significant once demographic and regional controls are included. This indicates that students exposed to higher television coverage during early childhood perform better academically across multiple subjects. The consistency of results across outcomes strengthens the credibility of the estimated relationship.\n",
    "\n",
    "**Math Achievement (math_std) Interpretation:**\n",
    "Higher television coverage interacted with sophomore status is associated with significantly higher standardized math scores. While sophomores in 1980 perform worse on average than non-sophomores, the positive interaction suggests that greater television access mitigates this gap. The sizable and statistically significant coefficients on demographic controls confirm the importance of socioeconomic factors in explaining math performance.\n",
    "\n",
    "**Vocabulary Achievement (vocab_std) Interpretation:**\n",
    "The estimated effect of television coverage is strongest for vocabulary outcomes. The positive and significant interaction term implies that early exposure to television content is particularly correlated with language development. As in the math regression, racial and family-structure controls explain a large share of outcome variation, but the coverage effect remains robust.\n",
    "\n",
    "**Reading Achievement (read_std) Interpretation:**\n",
    "Reading scores display the same qualitative pattern, with higher television coverage linked to better standardized reading performance for sophomores. Although the overall explanatory power is slightly lower than in math and vocabulary, the consistency in sign and significance suggests that television exposure affects a broad set of academic skills rather than a single subject.\n",
    "\n",
    "*Presenting three separate regressions allows the analysis to demonstrate that the relationship between television coverage and academic outcomes is systematic and robust, rather than driven by a single test score. This mirrors the structure and intent of Table 7 in the original paper.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bb14de7d-00c5-4671-88a3-f7c3121be85f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== math_std ===\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               math_std   R-squared:                       0.139\n",
      "Model:                            OLS   Adj. R-squared:                  0.138\n",
      "Method:                 Least Squares   F-statistic:                     713.1\n",
      "Date:                Fri, 12 Dec 2025   Prob (F-statistic):               0.00\n",
      "Time:                        07:20:19   Log-Likelihood:                -66743.\n",
      "No. Observations:               49678   AIC:                         1.335e+05\n",
      "Df Residuals:                   49664   BIC:                         1.336e+05\n",
      "Df Model:                          13                                         \n",
      "Covariance Type:                  HC1                                         \n",
      "======================================================================================================\n",
      "                                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Intercept                              0.3633      0.020     18.325      0.000       0.324       0.402\n",
      "censusregion[T.MIDDLE ATLANTIC]       -0.0183      0.022     -0.830      0.407      -0.061       0.025\n",
      "censusregion[T.SOUTH ATLANTIC]        -0.1393      0.022     -6.343      0.000      -0.182      -0.096\n",
      "censusregion[T.EAST SOUTH CENTRAL]    -0.3468      0.026    -13.444      0.000      -0.397      -0.296\n",
      "censusregion[T.WEST SOUTH CENTRAL]    -0.2688      0.023    -11.551      0.000      -0.314      -0.223\n",
      "censusregion[T.EAST NORTH CENTRAL]    -0.1156      0.021     -5.434      0.000      -0.157      -0.074\n",
      "censusregion[T.WEST NORTH CENTRAL]    -0.0603      0.024     -2.476      0.013      -0.108      -0.013\n",
      "censusregion[T.MOUNTAIN]              -0.2392      0.027     -8.913      0.000      -0.292      -0.187\n",
      "censusregion[T.PACIFIC]               -0.0742      0.023     -3.195      0.001      -0.120      -0.029\n",
      "cov_x_soph                             0.3700      0.087      4.244      0.000       0.199       0.541\n",
      "soph_1980                             -0.2089      0.051     -4.125      0.000      -0.308      -0.110\n",
      "black                                 -0.7644      0.012    -64.628      0.000      -0.788      -0.741\n",
      "hisp                                  -0.6591      0.012    -55.760      0.000      -0.682      -0.636\n",
      "singleparentsr                        -0.3324      0.013    -26.564      0.000      -0.357      -0.308\n",
      "==============================================================================\n",
      "Omnibus:                     2891.755   Durbin-Watson:                   1.774\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1100.742\n",
      "Skew:                           0.064   Prob(JB):                    9.48e-240\n",
      "Kurtosis:                       2.282   Cond. No.                         31.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC1)\n",
      "\n",
      "=== vocab_std ===\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              vocab_std   R-squared:                       0.147\n",
      "Model:                            OLS   Adj. R-squared:                  0.147\n",
      "Method:                 Least Squares   F-statistic:                     700.8\n",
      "Date:                Fri, 12 Dec 2025   Prob (F-statistic):               0.00\n",
      "Time:                        07:20:19   Log-Likelihood:                -67922.\n",
      "No. Observations:               50744   AIC:                         1.359e+05\n",
      "Df Residuals:                   50730   BIC:                         1.360e+05\n",
      "Df Model:                          13                                         \n",
      "Covariance Type:                  HC1                                         \n",
      "======================================================================================================\n",
      "                                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Intercept                              0.4378      0.019     22.943      0.000       0.400       0.475\n",
      "censusregion[T.MIDDLE ATLANTIC]       -0.0753      0.021     -3.562      0.000      -0.117      -0.034\n",
      "censusregion[T.SOUTH ATLANTIC]        -0.2268      0.021    -10.655      0.000      -0.268      -0.185\n",
      "censusregion[T.EAST SOUTH CENTRAL]    -0.4189      0.025    -16.763      0.000      -0.468      -0.370\n",
      "censusregion[T.WEST SOUTH CENTRAL]    -0.3884      0.023    -16.971      0.000      -0.433      -0.344\n",
      "censusregion[T.EAST NORTH CENTRAL]    -0.2188      0.020    -10.757      0.000      -0.259      -0.179\n",
      "censusregion[T.WEST NORTH CENTRAL]    -0.2051      0.024     -8.717      0.000      -0.251      -0.159\n",
      "censusregion[T.MOUNTAIN]              -0.2783      0.026    -10.658      0.000      -0.329      -0.227\n",
      "censusregion[T.PACIFIC]               -0.0783      0.022     -3.496      0.000      -0.122      -0.034\n",
      "cov_x_soph                             0.4347      0.085      5.119      0.000       0.268       0.601\n",
      "soph_1980                             -0.2383      0.049     -4.829      0.000      -0.335      -0.142\n",
      "black                                 -0.7883      0.013    -62.726      0.000      -0.813      -0.764\n",
      "hisp                                  -0.6845      0.012    -56.333      0.000      -0.708      -0.661\n",
      "singleparentsr                        -0.2826      0.013    -21.608      0.000      -0.308      -0.257\n",
      "==============================================================================\n",
      "Omnibus:                     1177.652   Durbin-Watson:                   1.761\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              677.479\n",
      "Skew:                          -0.116   Prob(JB):                    7.72e-148\n",
      "Kurtosis:                       2.483   Cond. No.                         31.4\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC1)\n",
      "\n",
      "=== read_std ===\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               read_std   R-squared:                       0.117\n",
      "Model:                            OLS   Adj. R-squared:                  0.117\n",
      "Method:                 Least Squares   F-statistic:                     561.0\n",
      "Date:                Fri, 12 Dec 2025   Prob (F-statistic):               0.00\n",
      "Time:                        07:20:19   Log-Likelihood:                -68474.\n",
      "No. Observations:               50503   AIC:                         1.370e+05\n",
      "Df Residuals:                   50489   BIC:                         1.371e+05\n",
      "Df Model:                          13                                         \n",
      "Covariance Type:                  HC1                                         \n",
      "======================================================================================================\n",
      "                                         coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "Intercept                              0.3120      0.019     16.054      0.000       0.274       0.350\n",
      "censusregion[T.MIDDLE ATLANTIC]       -0.0204      0.022     -0.944      0.345      -0.063       0.022\n",
      "censusregion[T.SOUTH ATLANTIC]        -0.1016      0.022     -4.692      0.000      -0.144      -0.059\n",
      "censusregion[T.EAST SOUTH CENTRAL]    -0.2181      0.025     -8.631      0.000      -0.268      -0.169\n",
      "censusregion[T.WEST SOUTH CENTRAL]    -0.2161      0.023     -9.329      0.000      -0.261      -0.171\n",
      "censusregion[T.EAST NORTH CENTRAL]    -0.0971      0.021     -4.667      0.000      -0.138      -0.056\n",
      "censusregion[T.WEST NORTH CENTRAL]    -0.0205      0.024     -0.850      0.395      -0.068       0.027\n",
      "censusregion[T.MOUNTAIN]              -0.1598      0.027     -6.018      0.000      -0.212      -0.108\n",
      "censusregion[T.PACIFIC]               -0.0660      0.023     -2.882      0.004      -0.111      -0.021\n",
      "cov_x_soph                             0.4141      0.088      4.719      0.000       0.242       0.586\n",
      "soph_1980                             -0.2244      0.051     -4.401      0.000      -0.324      -0.124\n",
      "black                                 -0.6993      0.012    -56.727      0.000      -0.724      -0.675\n",
      "hisp                                  -0.6522      0.012    -54.564      0.000      -0.676      -0.629\n",
      "singleparentsr                        -0.2689      0.013    -21.081      0.000      -0.294      -0.244\n",
      "==============================================================================\n",
      "Omnibus:                     2203.543   Durbin-Watson:                   1.842\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              918.281\n",
      "Skew:                           0.011   Prob(JB):                    3.96e-200\n",
      "Kurtosis:                       2.340   Cond. No.                         31.3\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors are heteroscedasticity robust (HC1)\n"
     ]
    }
   ],
   "source": [
    "controls = [\n",
    "    \"black\",\n",
    "    \"hisp\",\n",
    "    \"singleparentsr\",\n",
    "    \"censusregion\"\n",
    "]\n",
    "\n",
    "# Run identical specifications for math, vocabulary, and reading\n",
    "for y in [\"math_std\", \"vocab_std\", \"read_std\"]:\n",
    "    formula = f\"{y} ~ cov_x_soph + soph_1980 + \" + \" + \".join(controls)\n",
    "    model = smf.ols(formula, data=df).fit(cov_type=\"HC1\")\n",
    "    print(f\"\\n=== {y} ===\")\n",
    "    print(model.summary())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
